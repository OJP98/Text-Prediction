{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598112528515",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio #3 - Predicción de textos\n",
    "\n",
    "* Oscar Juárez - 17315\n",
    "* José Pablo Cifuentes - 17509\n",
    "* Paul Belches - 17088"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib\n",
    "from wordcloud import WordCloud\n",
    "import collections\n",
    "import random\n",
    "\n",
    "# Definirmos lista de stopwords según nltk\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación y limpieza de datos\n",
    "\n",
    "### 1. Abrir y leer archivos.\n",
    "\n",
    "Cabe mencionar que todos los archivos fueron convertidos a minúsculas, se quitan los urls y en algunas ocasiones, la mayoría de símbolos que consideramos innecesarios. También se quitan las stopwords, los números y finalmente las apostrophes. Además, se separan oraciones mediante los símbolos de **.**, **!** y **?**. Se debe validar que no hayan espacios vacíos luego de estas oraciones. \n",
    "\n",
    "#### Caso 1: Blogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# Se instancian arreglos\n",
    "blog = []\n",
    "\n",
    "with open('./files/en_US.blogs.txt', 'r', encoding='utf-8') as blog_txt:\n",
    "    for line in blog_txt:\n",
    "        # Quitar saltos de linea y pasar todo a minusculas\n",
    "        line = line.rstrip('\\n').lower()\n",
    "        # Quitar URLS\n",
    "        line = re.sub(r'^https?:\\/\\/.[\\r\\n]', '', line)\n",
    "        # Quitar el resto de expresiones regulares, excepto . ? ! y '\n",
    "        line = re.sub(r\"[^\\w.?!\\d'\\s]\", '', line)\n",
    "        # Quitar números\n",
    "        line = re.sub(r'[0-9]', ' ', line)\n",
    "        # Quitar espacios extra\n",
    "        line = line.strip(' \\t\\n\\r')\n",
    "        # Quitamos todas las stopwords\n",
    "        line = [word for word in line.split(' ') if word not in stopwords]\n",
    "        line = ' '.join(line)\n",
    "        #Finalmente, quitamos apostrofes\n",
    "        line = line.replace(\"'\", '')\n",
    "        # Separar posibles oraciones\n",
    "        dotSentences = line.split('.')\n",
    "        excSentences = line.split('!')\n",
    "        queSentences = line.split('?')\n",
    "\n",
    "        # Validar y verificar que valga la pena recorrer varias oraciones\n",
    "        if len(dotSentences) > 1:\n",
    "            for sentence in dotSentences:\n",
    "                # Por cada posible oración, debemos quitar los símbolos de puntuación\n",
    "                sentence = re.sub(r'[^\\w]', ' ', sentence).strip()\n",
    "                if len(sentence) > 1: blog.append(sentence)\n",
    "\n",
    "        elif len(excSentences) > 1:\n",
    "            for sentence in excSentences:\n",
    "                sentence = re.sub(r'[^\\w]', ' ', sentence)\n",
    "                if len(sentence) > 1: blog.append(sentence)\n",
    "        \n",
    "        elif len(queSentences) > 1:\n",
    "            for sentence in queSentences:\n",
    "                sentence = re.sub(r'[^\\w]', ' ', sentence)\n",
    "                if len(sentence) > 1: blog.append(sentence)\n",
    "\n",
    "        elif len(line.split(' ')) > 1:\n",
    "                line = re.sub(r'[^\\w]', ' ', line).strip()\n",
    "                blog.append(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caso 2: Noticias\n",
    "\n",
    "Este caso tuvo un procedimiento igual al caso 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "news = []\n",
    "\n",
    "with open('./files/en_US.news.txt', 'r', encoding='utf-8') as news_txt:\n",
    "    for line in news_txt:\n",
    "        # Quitar saltos de linea y pasar todo a minusculas\n",
    "        line = line.rstrip('\\n').lower()\n",
    "        # Quitar URLS\n",
    "        line = re.sub(r'^https?:\\/\\/.[\\r\\n]', '', line)\n",
    "        # Quitar el resto de expresiones regulares, excepto . ? ! y '\n",
    "        line = re.sub(r\"[^\\w.?!\\d'\\s]\", '', line)\n",
    "        # Quitar números\n",
    "        line = re.sub(r'[0-9]', ' ', line)\n",
    "        # Quitar espacios extra\n",
    "        line = line.strip(' \\t\\n\\r')\n",
    "        # Quitamos todas las stopwords\n",
    "        line = [word for word in line.split(' ') if word not in stopwords]\n",
    "        line = ' '.join(line)\n",
    "        #Finalmente, quitamos apostrofes\n",
    "        line = line.replace(\"'\", '')\n",
    "        # Separar posibles oraciones\n",
    "        dotSentences = line.split('.')\n",
    "        excSentences = line.split('!')\n",
    "        queSentences = line.split('?')\n",
    "\n",
    "        # Validar y verificar que valga la pena recorrer varias oraciones\n",
    "       if len(dotSentences) > 1:\n",
    "            for sentence in dotSentences:\n",
    "                # Por cada posible oración, debemos quitar los símbolos de puntuación\n",
    "                sentence = re.sub(r'[^\\w]', ' ', sentence).strip()\n",
    "                if len(sentence) > 1: news.append(sentence)\n",
    "\n",
    "        elif len(excSentences) > 1:\n",
    "            for sentence in excSentences:\n",
    "                sentence = re.sub(r'[^\\w]', ' ', sentence)\n",
    "                if len(sentence) > 1: news.append(sentence)\n",
    "        \n",
    "        elif len(queSentences) > 1:\n",
    "            for sentence in queSentences:\n",
    "                sentence = re.sub(r'[^\\w]', ' ', sentence)\n",
    "                if len(sentence) > 1: news.append(sentence)\n",
    "\n",
    "        elif len(line.split(' ')) > 1:\n",
    "        line = re.sub(r'[^\\w]', ' ', line).strip()\n",
    "        news.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caso 3: Twitter\n",
    "\n",
    "En este caso, se toma cada distinto tweet como una oración. Es necesario quitar emojis y símbolos como #, $, %, !, @, etc. Además, se quitan urls y se permiten los símbolos: **.** **,** **'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "\n",
    "with open('./files/en_US.twitter.txt', 'r', encoding='utf-8') as twitter_txt:\n",
    "    for line in twitter_txt:\n",
    "        # Quitar \\n y pasarlo a minusculas\n",
    "        line = line.replace('\\n', '').lower()\n",
    "        # Quitar URLS\n",
    "        line = re.sub(r'^https?:\\/\\/.[\\r\\n]', '', line)\n",
    "        # Quitar el resto de expresiones regulares, excepto . , y '\n",
    "        line = re.sub(r\"[^\\w.,\\d'\\s]\", '', line)\n",
    "        # Quitar números fuera de contexto\n",
    "        line = re.sub('^\\d+\\s|\\s\\d+\\s|\\s\\d+$', '', line)\n",
    "        # Añadirlos a la lista de tweets\n",
    "        tweets.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(blog + news + tweets, columns=[\"oraciones\"])\n",
    "df.to_csv('oraciones.csv', index=False)"
   ]
  }
 ]
}